{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Competitor NER & Sentiment Analysis - IMPROVED SENTIMENT MODEL\n",
    "\n",
    "**Performance Improvements Based on Feedback:**\n",
    "- NER Model: **90.2% F1** âœ… (Keep as is - excellent performance)\n",
    "- Sentiment Model: **58.0% F1** â†’ Target: **>70% F1** ðŸŽ¯\n",
    "\n",
    "**Sentiment Model Improvements:**\n",
    "1. âœ… **Data Augmentation** - Expand 212 training samples with synonym replacement, back-translation\n",
    "2. âœ… **Focal Loss** - Better handle class imbalance, focus on hard examples\n",
    "3. âœ… **Optimized Hyperparameters** - Lower LR (1e-5), more epochs (10), better warmup (0.2)\n",
    "4. âœ… **Early Stopping** - Stop when val F1 plateaus (patience=3)\n",
    "5. âœ… **Better Contextualization** - Improved prompt engineering\n",
    "6. âœ… **Detailed Analysis** - Confusion matrix, per-class metrics, error analysis\n",
    "\n",
    "**Expected Performance:**\n",
    "- NER F1: **>0.90** (maintained)\n",
    "- Sentiment F1: **>0.70** (improved from 0.58)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required libraries\n",
    "!pip install -q transformers datasets torch torchvision accelerate\n",
    "!pip install -q scikit-learn pandas numpy matplotlib seaborn\n",
    "!pip install -q sentencepiece protobuf\n",
    "!pip install -q openpyxl xlsxwriter\n",
    "!pip install -q chardet\n",
    "!pip install -q nltk  # For data augmentation\n",
    "!pip install -q nlpaug  # Advanced augmentation\n",
    "\n",
    "# Download NLTK data for augmentation\n",
    "import nltk\n",
    "nltk.download('wordnet', quiet=True)\n",
    "nltk.download('omw-1.4', quiet=True)\n",
    "nltk.download('averaged_perceptron_tagger', quiet=True)\n",
    "print(\"âœ“ NLTK data downloaded for augmentation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import gc\n",
    "import warnings\n",
    "import chardet\n",
    "from pathlib import Path\n",
    "from copy import deepcopy\n",
    "import random\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torch.optim import AdamW\n",
    "\n",
    "# Transformers\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForSequenceClassification,\n",
    "    get_linear_schedule_with_warmup,\n",
    "    get_cosine_schedule_with_warmup\n",
    ")\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix,\n",
    "    accuracy_score, f1_score, precision_recall_fscore_support\n",
    ")\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Augmentation\n",
    "import nlpaug.augmenter.word as naw\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Set seeds\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "random.seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "print(\"âœ“ Libraries imported successfully!\")\n",
    "print(f\"âœ“ PyTorch version: {torch.__version__}\")\n",
    "print(f\"âœ“ Using AdamW from: torch.optim\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU and configure device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    gpu_props = torch.cuda.get_device_properties(0)\n",
    "    gpu_memory_gb = gpu_props.total_memory / 1e9\n",
    "    print(f\"GPU: {gpu_props.name}\")\n",
    "    print(f\"GPU Memory: {gpu_memory_gb:.2f} GB\")\n",
    "    \n",
    "    # Adaptive batch size\n",
    "    if gpu_memory_gb >= 15:\n",
    "        BATCH_SIZE = 16\n",
    "        GRAD_ACCUM_STEPS = 2\n",
    "    else:\n",
    "        BATCH_SIZE = 8\n",
    "        GRAD_ACCUM_STEPS = 4\n",
    "else:\n",
    "    BATCH_SIZE = 4\n",
    "    GRAD_ACCUM_STEPS = 8\n",
    "\n",
    "EFFECTIVE_BATCH_SIZE = BATCH_SIZE * GRAD_ACCUM_STEPS\n",
    "print(f\"\\nBatch size: {BATCH_SIZE}, Accumulation: {GRAD_ACCUM_STEPS}, Effective: {EFFECTIVE_BATCH_SIZE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Create directories\n",
    "!mkdir -p '/content/drive/MyDrive/KFC_ML_Models'\n",
    "!mkdir -p '/content/results'\n",
    "\n",
    "MODEL_SAVE_DIR = '/content/drive/MyDrive/KFC_ML_Models'\n",
    "RESULTS_DIR = '/content/results'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Competitor list (14 total)\n",
    "COMPETITORS = [\n",
    "    'Burger King', 'Deliveroo', \"Domino's\", 'Five Guys', 'Greggs',\n",
    "    'Just Eat', 'KFC', \"McDonald's\", \"Nando's\", \"Papa John's\",\n",
    "    'Pizza Hut', 'Pret a Manger', 'Taco Bell', 'Uber Eats'\n",
    "]\n",
    "\n",
    "SENTIMENT_MAP = {0: 'negative', 1: 'neutral', 2: 'positive'}\n",
    "\n",
    "# Model configs\n",
    "NER_MODEL_NAME = 'bert-base-uncased'\n",
    "SENTIMENT_MODEL_NAME = 'cardiffnlp/twitter-roberta-base-sentiment-latest'\n",
    "\n",
    "# Hyperparameters\n",
    "MAX_SEQ_LENGTH = 128\n",
    "\n",
    "# NER hyperparameters (keep same - performing well)\n",
    "NER_LEARNING_RATE = 2e-5\n",
    "NER_EPOCHS = 5\n",
    "NER_WARMUP_RATIO = 0.1\n",
    "\n",
    "# IMPROVED Sentiment hyperparameters\n",
    "SENTIMENT_LEARNING_RATE = 1e-5  # Lower LR for better fine-tuning\n",
    "SENTIMENT_EPOCHS = 10  # More epochs\n",
    "SENTIMENT_WARMUP_RATIO = 0.2  # More warmup\n",
    "SENTIMENT_EARLY_STOP_PATIENCE = 3  # Early stopping\n",
    "\n",
    "# Data Augmentation settings\n",
    "AUGMENTATION_FACTOR = 3  # Create 3x more training data\n",
    "\n",
    "# Other\n",
    "WEIGHT_DECAY = 0.01\n",
    "FOCAL_LOSS_GAMMA = 2.0  # Focal loss parameter\n",
    "\n",
    "print(f\"âœ“ Configuration loaded\")\n",
    "print(f\"  Competitors: {len(COMPETITORS)}\")\n",
    "print(f\"  NER Model: {NER_MODEL_NAME}\")\n",
    "print(f\"  Sentiment Model: {SENTIMENT_MODEL_NAME}\")\n",
    "print(f\"\\nðŸŽ¯ SENTIMENT MODEL IMPROVEMENTS:\")\n",
    "print(f\"  Learning Rate: {SENTIMENT_LEARNING_RATE} (was 2e-5)\")\n",
    "print(f\"  Epochs: {SENTIMENT_EPOCHS} (was 5)\")\n",
    "print(f\"  Warmup Ratio: {SENTIMENT_WARMUP_RATIO} (was 0.1)\")\n",
    "print(f\"  Augmentation Factor: {AUGMENTATION_FACTOR}x\")\n",
    "print(f\"  Early Stopping: Patience {SENTIMENT_EARLY_STOP_PATIENCE}\")\n",
    "print(f\"  Focal Loss Gamma: {FOCAL_LOSS_GAMMA}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
